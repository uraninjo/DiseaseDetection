{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/15.1M [00:00<?, ?B/s]\n",
      "  7%|▋         | 1.00M/15.1M [00:00<00:04, 3.32MB/s]\n",
      " 20%|█▉        | 3.00M/15.1M [00:00<00:01, 8.71MB/s]\n",
      " 40%|███▉      | 6.00M/15.1M [00:00<00:00, 14.8MB/s]\n",
      " 60%|█████▉    | 9.00M/15.1M [00:00<00:00, 18.5MB/s]\n",
      " 79%|███████▉  | 12.0M/15.1M [00:00<00:00, 21.0MB/s]\n",
      " 99%|█████████▉| 15.0M/15.1M [00:00<00:00, 22.7MB/s]\n",
      "100%|██████████| 15.1M/15.1M [00:00<00:00, 17.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading brain-mri-images-for-brain-tumor-detection.zip to c:\\Users\\mehmu\\Desktop\\PyProjects\\Projects\\github repo\\DiseaseDetection\\TumorDataset\n",
      "\n",
      "brain-mri-images-for-brain-tumor-detection.zip\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d navoneel/brain-mri-images-for-brain-tumor-detection\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import os,time\n",
    "for i in os.listdir('C:/Users/mehmu/Desktop/PyProjects/Projects/github repo/DiseaseDetection/TumorDataset'):\n",
    "    if '.zip' in i:\n",
    "        print(i)\n",
    "        with ZipFile(i, 'r') as zipObj:\n",
    "            zipObj.extractall()\n",
    "        os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import tensorflow \n",
    "\n",
    "\n",
    "import scipy\n",
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# Set the seed value for experiment reproduci.bility.\n",
    "seed = 1842\n",
    "tensorflow.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# Turn off warnings for cleaner looking notebook\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 images belonging to 2 classes.\n",
      "Found 83 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.33, shear_range =.25, horizontal_flip = True, rotation_range=20)     \n",
    "\n",
    "\n",
    "train_dataset = image_generator.flow_from_directory(batch_size=8,\n",
    "                                                 directory='brain_tumor_dataset',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(512,512), \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_dataset = image_generator.flow_from_directory(batch_size=8,\n",
    "                                                 directory='brain_tumor_dataset',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(512,512), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape = [512,512,3]),\n",
    "keras.layers.MaxPooling2D(),\n",
    "keras.layers.Conv2D(32, (2, 2), activation='relu'),\n",
    "keras.layers.MaxPooling2D(),\n",
    "\n",
    "keras.layers.SeparableConv2D(64, 3, activation='relu', padding='same'),\n",
    "keras.layers.SeparableConv2D(64, 3, activation='relu', padding='same'),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPool2D(),\n",
    "\n",
    "keras.layers.SeparableConv2D(128, 3, activation='relu', padding='same'),\n",
    "keras.layers.SeparableConv2D(128, 3, activation='relu', padding='same'),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPool2D(),\n",
    "keras.layers.Dropout(0.2),\n",
    "\n",
    "keras.layers.SeparableConv2D(256, 3, activation='relu', padding='same'),\n",
    "keras.layers.SeparableConv2D(256, 3, activation='relu', padding='same'),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.MaxPool2D(),\n",
    "keras.layers.Dropout(0.2),\n",
    "\n",
    "keras.layers.Flatten(),\n",
    "\n",
    "keras.layers.Dense(512, activation='relu'),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(0.5),\n",
    "\n",
    "keras.layers.Dense(128, activation='relu'),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(0.5),\n",
    "\n",
    "keras.layers.Dense(64, activation='relu'),\n",
    "keras.layers.BatchNormalization(),\n",
    "keras.layers.Dropout(0.3),\n",
    "\n",
    "keras.layers.Dense(2, activation ='softmax')])\n",
    "\n",
    "model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tensorflow.losses.CategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.AUC(name='auc'),'acc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 **(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"tumor_model.h5\",\n",
    "                                                    save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_acc',patience=10,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 14s 557ms/step - loss: 0.9084 - auc: 0.6029 - acc: 0.5882 - val_loss: 4.3744 - val_auc: 0.6145 - val_acc: 0.6145 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 14s 643ms/step - loss: 0.7560 - auc: 0.7087 - acc: 0.6588 - val_loss: 1.3863 - val_auc: 0.7949 - val_acc: 0.7590 - lr: 0.0089\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 12s 554ms/step - loss: 0.6774 - auc: 0.6934 - acc: 0.6412 - val_loss: 0.8612 - val_auc: 0.7790 - val_acc: 0.7349 - lr: 0.0079\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 11s 525ms/step - loss: 0.6307 - auc: 0.7097 - acc: 0.6529 - val_loss: 22.2902 - val_auc: 0.3855 - val_acc: 0.3855 - lr: 0.0071\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 11s 507ms/step - loss: 0.7000 - auc: 0.6133 - acc: 0.5941 - val_loss: 1.2206 - val_auc: 0.6995 - val_acc: 0.6024 - lr: 0.0063\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 11s 495ms/step - loss: 0.6162 - auc: 0.7422 - acc: 0.6941 - val_loss: 8.3818 - val_auc: 0.3279 - val_acc: 0.3855 - lr: 0.0056\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 11s 504ms/step - loss: 0.5743 - auc: 0.7782 - acc: 0.7000 - val_loss: 1.4265 - val_auc: 0.7515 - val_acc: 0.6145 - lr: 0.0050\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 12s 537ms/step - loss: 0.5380 - auc: 0.8051 - acc: 0.7529 - val_loss: 0.6632 - val_auc: 0.7855 - val_acc: 0.6386 - lr: 0.0045\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 11s 505ms/step - loss: 0.5705 - auc: 0.7812 - acc: 0.7294 - val_loss: 2.4287 - val_auc: 0.2876 - val_acc: 0.3735 - lr: 0.0040\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 11s 511ms/step - loss: 0.6073 - auc: 0.7430 - acc: 0.6471 - val_loss: 2.0521 - val_auc: 0.2909 - val_acc: 0.4096 - lr: 0.0035\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 0.5982 - auc: 0.7521 - acc: 0.6765 - val_loss: 2.2480 - val_auc: 0.2842 - val_acc: 0.3614 - lr: 0.0032\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 12s 565ms/step - loss: 0.6312 - auc: 0.6906 - acc: 0.6059 - val_loss: 10.8114 - val_auc: 0.3603 - val_acc: 0.3855 - lr: 0.0028\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 305ms/step - loss: 1.4274 - auc: 0.7824 - acc: 0.7470\n",
      "Loss:  1.427358627319336\n",
      "AUC:  0.782406747341156\n",
      "Accuracy:  0.7469879388809204\n"
     ]
    }
   ],
   "source": [
    "loss, auc, accuracy = model.evaluate(validation_dataset)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"AUC: \", auc)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 253 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1/255, validation_split=0, shear_range =.25, horizontal_flip = True)\n",
    "\n",
    "\n",
    "test = image_generator.flow_from_directory(batch_size=8,\n",
    "                                                    directory='brain_tumor_dataset',\n",
    "                                                    shuffle=True,\n",
    "                                                    target_size=(512,512),\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 11s 336ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.argmax(model.predict(test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3753009147809343"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,accuracy_score,f1_score\n",
    "\n",
    "r2_score(y_pred,test.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5375494071146245"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,test.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656891495601173"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,test.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7d98f6a89a2cc2c3b451a8bb432008958aa7c83c5ffc793c3e15255d944d91d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
